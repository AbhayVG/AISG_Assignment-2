{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c7247315",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from datasets import Dataset\n",
    "from unsloth import FastLanguageModel\n",
    "from transformers import TrainingArguments, Trainer, EvalPrediction\n",
    "import torch\n",
    "from peft import LoraConfig\n",
    "from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score\n",
    "\n",
    "# -------------------------------------------------------------------\n",
    "# 1. LOAD DATA\n",
    "# -------------------------------------------------------------------\n",
    "train_df = pd.read_csv(\"medical_cases_train/medical_cases_train.csv\")[[\"description\", \"transcription\"]].dropna()\n",
    "val_df = pd.read_csv(\"medical_cases_validation/medical_cases_validation.csv\")[[\"description\", \"transcription\"]].dropna()\n",
    "test_df = pd.read_csv(\"medical_cases_test/medical_cases_test.csv\")[[\"description\", \"transcription\"]].dropna()\n",
    "\n",
    "train_dataset = Dataset.from_pandas(train_df)\n",
    "val_dataset = Dataset.from_pandas(val_df)\n",
    "test_dataset = Dataset.from_pandas(test_df)\n",
    "\n",
    "# -------------------------------------------------------------------\n",
    "# 2. FORMAT PROMPTS\n",
    "# -------------------------------------------------------------------\n",
    "def format_prompt(example):\n",
    "    return {\n",
    "        \"text\": f\"<start_of_turn>user\\n{example['description']}\\n<end_of_turn>\\n<start_of_turn>model\\n{example['transcription']}<end_of_turn>\"\n",
    "    }\n",
    "\n",
    "train_dataset = train_dataset.map(format_prompt)\n",
    "val_dataset = val_dataset.map(format_prompt)\n",
    "test_dataset = test_dataset.map(format_prompt)\n",
    "\n",
    "# -------------------------------------------------------------------\n",
    "# 3. LOAD MODEL\n",
    "# -------------------------------------------------------------------\n",
    "model_name = \"deepseek-ai/DeepSeek-R1-7B\"\n",
    "model, tokenizer = FastLanguageModel.from_pretrained(\n",
    "    model_name=model_name,\n",
    "    max_seq_length=512,\n",
    "    dtype=None,\n",
    "    load_in_4bit=True\n",
    ")\n",
    "tokenizer.pad_token = tokenizer.eos_token\n",
    "\n",
    "# -------------------------------------------------------------------\n",
    "# 4. APPLY LoRA\n",
    "# -------------------------------------------------------------------\n",
    "FastLanguageModel.for_training(model)\n",
    "\n",
    "lora_config = LoraConfig(\n",
    "    r=8,\n",
    "    lora_alpha=32,\n",
    "    target_modules=[\"q_proj\", \"v_proj\"],\n",
    "    lora_dropout=0.05,\n",
    "    bias=\"none\",\n",
    "    task_type=\"CAUSAL_LM\"\n",
    ")\n",
    "model.add_adapter(lora_config)\n",
    "\n",
    "# -------------------------------------------------------------------\n",
    "# 5. TOKENIZATION\n",
    "# -------------------------------------------------------------------\n",
    "def tokenize(example):\n",
    "    tokens = tokenizer(example[\"text\"], padding=\"max_length\", truncation=True, max_length=512)\n",
    "    tokens[\"labels\"] = tokens[\"input_ids\"].copy()\n",
    "    return tokens\n",
    "\n",
    "train_dataset = train_dataset.map(tokenize, remove_columns=train_dataset.column_names)\n",
    "val_dataset = val_dataset.map(tokenize, remove_columns=val_dataset.column_names)\n",
    "test_dataset = test_dataset.map(tokenize, remove_columns=test_dataset.column_names)\n",
    "\n",
    "# -------------------------------------------------------------------\n",
    "# 6. TRAINING ARGUMENTS\n",
    "# -------------------------------------------------------------------\n",
    "training_args = TrainingArguments(\n",
    "    output_dir=\"./gemma-lora-medical\",\n",
    "    per_device_train_batch_size=2,\n",
    "    gradient_accumulation_steps=4,\n",
    "    warmup_steps=10,\n",
    "    num_train_epochs=6,\n",
    "    learning_rate=2e-4,\n",
    "    fp16=True,\n",
    "    logging_dir=\"./logs\",\n",
    "    logging_steps=10,\n",
    "    save_strategy=\"epoch\",\n",
    "    save_total_limit=2,\n",
    "    report_to=\"none\"\n",
    ")\n",
    "\n",
    "\n",
    "# -------------------------------------------------------------------\n",
    "# 7. METRICS FUNCTION\n",
    "# -------------------------------------------------------------------\n",
    "def compute_metrics(eval_pred: EvalPrediction):\n",
    "    preds = eval_pred.predictions.argmax(-1)\n",
    "    labels = eval_pred.label_ids\n",
    "\n",
    "    # Flatten and ignore padded tokens\n",
    "    true_labels = []\n",
    "    pred_labels = []\n",
    "    for pred, label in zip(preds, labels):\n",
    "        for p, l in zip(pred, label):\n",
    "            if l != -100:\n",
    "                true_labels.append(l)\n",
    "                pred_labels.append(p)\n",
    "\n",
    "    return {\n",
    "        \"accuracy\": accuracy_score(true_labels, pred_labels),\n",
    "        \"precision\": precision_score(true_labels, pred_labels, average='macro', zero_division=0),\n",
    "        \"recall\": recall_score(true_labels, pred_labels, average='macro', zero_division=0),\n",
    "        \"f1\": f1_score(true_labels, pred_labels, average='macro', zero_division=0),\n",
    "    }\n",
    "\n",
    "# -------------------------------------------------------------------\n",
    "# 8. TRAINER\n",
    "# -------------------------------------------------------------------\n",
    "trainer = Trainer(\n",
    "    model=model,\n",
    "    args=training_args,\n",
    "    train_dataset=train_dataset,\n",
    "    eval_dataset=val_dataset,\n",
    "    tokenizer=tokenizer,\n",
    "    compute_metrics=compute_metrics\n",
    ")\n",
    "\n",
    "trainer.train()\n",
    "\n",
    "# -------------------------------------------------------------------\n",
    "# 9. FINAL TEST EVALUATION\n",
    "# -------------------------------------------------------------------\n",
    "print(\"\\n=== Final Evaluation on Test Set ===\")\n",
    "test_results = trainer.evaluate(eval_dataset=test_dataset)\n",
    "for key, value in test_results.items():\n",
    "    print(f\"{key}: {value:.4f}\")\n",
    "\n",
    "# -------------------------------------------------------------------\n",
    "# 10. SAVE MODEL\n",
    "# -------------------------------------------------------------------\n",
    "model.save_pretrained(\"./gemma-lora-medical\")\n",
    "tokenizer.save_pretrained(\"./gemma-lora-medical\")\n"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
