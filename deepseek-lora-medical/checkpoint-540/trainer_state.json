{
  "best_global_step": null,
  "best_metric": null,
  "best_model_checkpoint": null,
  "epoch": 5.0,
  "eval_steps": 500,
  "global_step": 540,
  "is_hyper_param_search": false,
  "is_local_process_zero": true,
  "is_world_process_zero": true,
  "log_history": [
    {
      "epoch": 0.09280742459396751,
      "grad_norm": 9.221386909484863,
      "learning_rate": 0.00018,
      "loss": 4.235,
      "step": 10
    },
    {
      "epoch": 0.18561484918793503,
      "grad_norm": 1.1724554300308228,
      "learning_rate": 0.00019715189873417723,
      "loss": 3.3183,
      "step": 20
    },
    {
      "epoch": 0.27842227378190254,
      "grad_norm": 0.6461237668991089,
      "learning_rate": 0.0001939873417721519,
      "loss": 2.9908,
      "step": 30
    },
    {
      "epoch": 0.37122969837587005,
      "grad_norm": 0.5542646050453186,
      "learning_rate": 0.00019082278481012658,
      "loss": 2.8736,
      "step": 40
    },
    {
      "epoch": 0.46403712296983757,
      "grad_norm": 0.5077370405197144,
      "learning_rate": 0.00018765822784810128,
      "loss": 2.671,
      "step": 50
    },
    {
      "epoch": 0.5568445475638051,
      "grad_norm": 0.4419770836830139,
      "learning_rate": 0.00018449367088607595,
      "loss": 2.688,
      "step": 60
    },
    {
      "epoch": 0.6496519721577726,
      "grad_norm": 0.463919073343277,
      "learning_rate": 0.00018132911392405062,
      "loss": 2.5882,
      "step": 70
    },
    {
      "epoch": 0.7424593967517401,
      "grad_norm": 0.4019034504890442,
      "learning_rate": 0.00017816455696202533,
      "loss": 2.4893,
      "step": 80
    },
    {
      "epoch": 0.8352668213457076,
      "grad_norm": 0.5330941677093506,
      "learning_rate": 0.000175,
      "loss": 2.4348,
      "step": 90
    },
    {
      "epoch": 0.9280742459396751,
      "grad_norm": 0.4664672315120697,
      "learning_rate": 0.0001718354430379747,
      "loss": 2.5603,
      "step": 100
    },
    {
      "epoch": 1.0185614849187936,
      "grad_norm": 0.4460100829601288,
      "learning_rate": 0.0001686708860759494,
      "loss": 2.4807,
      "step": 110
    },
    {
      "epoch": 1.111368909512761,
      "grad_norm": 0.502659022808075,
      "learning_rate": 0.00016550632911392404,
      "loss": 2.4332,
      "step": 120
    },
    {
      "epoch": 1.2041763341067284,
      "grad_norm": 0.4679217040538788,
      "learning_rate": 0.00016234177215189875,
      "loss": 2.3626,
      "step": 130
    },
    {
      "epoch": 1.296983758700696,
      "grad_norm": 0.5519333481788635,
      "learning_rate": 0.00015917721518987342,
      "loss": 2.3932,
      "step": 140
    },
    {
      "epoch": 1.3897911832946637,
      "grad_norm": 0.49265256524086,
      "learning_rate": 0.00015601265822784812,
      "loss": 2.3822,
      "step": 150
    },
    {
      "epoch": 1.482598607888631,
      "grad_norm": 0.49669769406318665,
      "learning_rate": 0.0001528481012658228,
      "loss": 2.4317,
      "step": 160
    },
    {
      "epoch": 1.5754060324825985,
      "grad_norm": 0.5226970314979553,
      "learning_rate": 0.00014968354430379747,
      "loss": 2.3061,
      "step": 170
    },
    {
      "epoch": 1.668213457076566,
      "grad_norm": 0.4869525730609894,
      "learning_rate": 0.00014651898734177217,
      "loss": 2.3352,
      "step": 180
    },
    {
      "epoch": 1.7610208816705337,
      "grad_norm": 0.5628586411476135,
      "learning_rate": 0.00014335443037974684,
      "loss": 2.4141,
      "step": 190
    },
    {
      "epoch": 1.8538283062645011,
      "grad_norm": 0.5727745890617371,
      "learning_rate": 0.0001401898734177215,
      "loss": 2.3115,
      "step": 200
    },
    {
      "epoch": 1.9466357308584685,
      "grad_norm": 0.5465204119682312,
      "learning_rate": 0.0001370253164556962,
      "loss": 2.4195,
      "step": 210
    },
    {
      "epoch": 2.0371229698375872,
      "grad_norm": 0.5301377177238464,
      "learning_rate": 0.00013386075949367089,
      "loss": 2.2163,
      "step": 220
    },
    {
      "epoch": 2.1299303944315544,
      "grad_norm": 0.5700052976608276,
      "learning_rate": 0.00013069620253164559,
      "loss": 2.2953,
      "step": 230
    },
    {
      "epoch": 2.222737819025522,
      "grad_norm": 0.6424797177314758,
      "learning_rate": 0.00012753164556962026,
      "loss": 2.3758,
      "step": 240
    },
    {
      "epoch": 2.3155452436194897,
      "grad_norm": 0.607964038848877,
      "learning_rate": 0.00012436708860759493,
      "loss": 2.3243,
      "step": 250
    },
    {
      "epoch": 2.408352668213457,
      "grad_norm": 0.6101956963539124,
      "learning_rate": 0.00012120253164556963,
      "loss": 2.3204,
      "step": 260
    },
    {
      "epoch": 2.5011600928074245,
      "grad_norm": 0.5939570665359497,
      "learning_rate": 0.00011803797468354432,
      "loss": 2.3401,
      "step": 270
    },
    {
      "epoch": 2.593967517401392,
      "grad_norm": 0.5915055274963379,
      "learning_rate": 0.00011487341772151898,
      "loss": 2.146,
      "step": 280
    },
    {
      "epoch": 2.6867749419953597,
      "grad_norm": 0.6091966032981873,
      "learning_rate": 0.00011170886075949368,
      "loss": 2.2899,
      "step": 290
    },
    {
      "epoch": 2.7795823665893273,
      "grad_norm": 0.6608506441116333,
      "learning_rate": 0.00010854430379746837,
      "loss": 2.2765,
      "step": 300
    },
    {
      "epoch": 2.8723897911832945,
      "grad_norm": 0.62044757604599,
      "learning_rate": 0.00010537974683544305,
      "loss": 2.2531,
      "step": 310
    },
    {
      "epoch": 2.965197215777262,
      "grad_norm": 0.6417924761772156,
      "learning_rate": 0.00010221518987341771,
      "loss": 2.1733,
      "step": 320
    },
    {
      "epoch": 3.0556844547563804,
      "grad_norm": 0.6563788652420044,
      "learning_rate": 9.90506329113924e-05,
      "loss": 2.312,
      "step": 330
    },
    {
      "epoch": 3.148491879350348,
      "grad_norm": 0.61611407995224,
      "learning_rate": 9.58860759493671e-05,
      "loss": 2.1888,
      "step": 340
    },
    {
      "epoch": 3.2412993039443156,
      "grad_norm": 0.6035988330841064,
      "learning_rate": 9.272151898734177e-05,
      "loss": 2.2261,
      "step": 350
    },
    {
      "epoch": 3.3341067285382833,
      "grad_norm": 0.6975761651992798,
      "learning_rate": 8.955696202531646e-05,
      "loss": 2.1681,
      "step": 360
    },
    {
      "epoch": 3.4269141531322505,
      "grad_norm": 0.5868370532989502,
      "learning_rate": 8.639240506329115e-05,
      "loss": 2.2251,
      "step": 370
    },
    {
      "epoch": 3.519721577726218,
      "grad_norm": 0.6005872488021851,
      "learning_rate": 8.322784810126583e-05,
      "loss": 2.2444,
      "step": 380
    },
    {
      "epoch": 3.6125290023201857,
      "grad_norm": 0.6317876577377319,
      "learning_rate": 8.006329113924052e-05,
      "loss": 2.1958,
      "step": 390
    },
    {
      "epoch": 3.705336426914153,
      "grad_norm": 0.6457772850990295,
      "learning_rate": 7.689873417721519e-05,
      "loss": 2.3322,
      "step": 400
    },
    {
      "epoch": 3.7981438515081205,
      "grad_norm": 0.6100733876228333,
      "learning_rate": 7.373417721518988e-05,
      "loss": 2.2624,
      "step": 410
    },
    {
      "epoch": 3.890951276102088,
      "grad_norm": 0.5676988363265991,
      "learning_rate": 7.056962025316457e-05,
      "loss": 2.1733,
      "step": 420
    },
    {
      "epoch": 3.9837587006960558,
      "grad_norm": 0.6664937734603882,
      "learning_rate": 6.740506329113925e-05,
      "loss": 2.1702,
      "step": 430
    },
    {
      "epoch": 4.0742459396751745,
      "grad_norm": 0.6799048185348511,
      "learning_rate": 6.424050632911393e-05,
      "loss": 2.245,
      "step": 440
    },
    {
      "epoch": 4.167053364269141,
      "grad_norm": 0.5783584117889404,
      "learning_rate": 6.107594936708861e-05,
      "loss": 2.1583,
      "step": 450
    },
    {
      "epoch": 4.259860788863109,
      "grad_norm": 0.6659972667694092,
      "learning_rate": 5.791139240506329e-05,
      "loss": 2.2705,
      "step": 460
    },
    {
      "epoch": 4.352668213457076,
      "grad_norm": 0.6179835200309753,
      "learning_rate": 5.474683544303798e-05,
      "loss": 2.2214,
      "step": 470
    },
    {
      "epoch": 4.445475638051044,
      "grad_norm": 0.6316336989402771,
      "learning_rate": 5.158227848101266e-05,
      "loss": 2.2279,
      "step": 480
    },
    {
      "epoch": 4.538283062645012,
      "grad_norm": 0.6392046809196472,
      "learning_rate": 4.8417721518987346e-05,
      "loss": 2.1622,
      "step": 490
    },
    {
      "epoch": 4.631090487238979,
      "grad_norm": 0.654193639755249,
      "learning_rate": 4.525316455696203e-05,
      "loss": 2.1775,
      "step": 500
    },
    {
      "epoch": 4.723897911832947,
      "grad_norm": 0.6462125778198242,
      "learning_rate": 4.208860759493671e-05,
      "loss": 2.2519,
      "step": 510
    },
    {
      "epoch": 4.816705336426914,
      "grad_norm": 0.6505022048950195,
      "learning_rate": 3.89240506329114e-05,
      "loss": 2.1581,
      "step": 520
    },
    {
      "epoch": 4.909512761020881,
      "grad_norm": 0.6571826934814453,
      "learning_rate": 3.575949367088608e-05,
      "loss": 2.1514,
      "step": 530
    },
    {
      "epoch": 5.0,
      "grad_norm": 0.7126632332801819,
      "learning_rate": 3.2594936708860766e-05,
      "loss": 2.172,
      "step": 540
    }
  ],
  "logging_steps": 10,
  "max_steps": 642,
  "num_input_tokens_seen": 0,
  "num_train_epochs": 6,
  "save_steps": 500,
  "stateful_callbacks": {
    "TrainerControl": {
      "args": {
        "should_epoch_stop": false,
        "should_evaluate": false,
        "should_log": false,
        "should_save": true,
        "should_training_stop": false
      },
      "attributes": {}
    }
  },
  "total_flos": 4.09073943576576e+16,
  "train_batch_size": 4,
  "trial_name": null,
  "trial_params": null
}
